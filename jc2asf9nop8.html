<div>tin</div><div>Now, however,  we encounter an apparent conundrum: the main point of the curve fit is to determine a best possible value for&nbsp;&nbsp;<span class="math ltx_Math v1">\(V_0\)</span> (among other variables) but solving for&nbsp;<span class="math ltx_Math v1">\(\delta V\)</span> requires a numerical value for&nbsp;<span class="math ltx_Math v1">\(V_0\)</span>. How do we determine the numerical values for &nbsp;<span class="math ltx_Math v1">\(\delta V_{pd}\left(\theta\right)\)</span> needed&nbsp; to find a best estimate of&nbsp;<span class="math ltx_Math v1">\(V_0\)</span> if we don't already know&nbsp;<span class="math ltx_Math v1">\(V_0\)</span>? This&nbsp; is not the impasse that it might seem because the curve fitting algorithm always requires that we  supply an initial guess for the parameters. In this situation,&nbsp; however, we   carry out the curve fitting algorithm repeatedly instead of just once, using the best fit values output by the algorithm as our new initial values. Once the output values match the input values  (within uncertainty), we stop. When the output values match the input values, we say the results are <i>self-consistent.</i></div><div></div><div> <b>Here  is the procedure for finding self-consistent 'best fit' values for&nbsp;</b><span class="math ltx_Math v1">\(V_0\)</span><b> ,&nbsp;</b><span class="math ltx_Math v1">\(V_1\)</span><b>, and&nbsp;</b><span class="math ltx_Math v1">\(\theta_0\)</span><b> from the curve-fitting routine</b>:&nbsp;</div><div> </div><ol><li>Make  a  rough initial guess for the  parameters&nbsp;<span class="math ltx_Math v1">\(V_0\)</span>,&nbsp;<span class="math ltx_Math v1">\(V_1\)</span>, and&nbsp;<span class="math ltx_Math v1">\(\theta_0\)</span> from a graph of the data.</li><li>Use the values of&nbsp; <span class="math ltx_Math v1">\(V_0\)</span>,&nbsp;<span class="math ltx_Math v1">\(V_1\)</span>, and&nbsp;<span class="math ltx_Math v1">\(\theta_0\)</span> output by the curve-fitting routine as a new 'initial guess'</li><li>Repeat the curve fit&nbsp; (using each  output as a new input) until&nbsp;<span class="math ltx_Math v1">\(V_0\)</span> stops changing.&nbsp; </li></ol><div>Note: if you know how to do  programming in Python, this would be a great place to introduce a&nbsp;<b> loop</b> into the code. Because we want this guide to be useful even to beginners, we haven't done that here (see FIg. <span class="au-ref raw v1">\ref{627293}</span> for attached code ) but we do plan to add a section on how to do that sometime in the future. </div><div></div><h2 data-label="205170" class="ltx_title_subsection">fitting the model to data</h2><h3 data-label="305318" class="ltx_title_subsubsection">calculating best fit values</h3><div></div><div>We now turn to the actual Python code for non-linear curve fitting. Notice that&nbsp; this is a&nbsp; "weighted" fit, in that the stated uncertainty of each data point is taken into account during the fit. Practically speaking, this means the curve-fitting routine tries harder to match the model to the data at points with a smaller uncertainty (although it may not succeed) because those points are given greater importance ('weight'). </div><div></div><div>Here we assume that values have already been experimentally determined for uncertainties in&nbsp;&nbsp;<span class="math ltx_Math v1">\(V_0\)</span>,&nbsp;<span class="math ltx_Math v1">\(V_1\)</span>, and&nbsp;<span class="math ltx_Math v1">\(\theta\)</span>. We will leave these unchanged throughout the curve-fitting process.&nbsp; </div>